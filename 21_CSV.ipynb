{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is a CSV File?\n",
    "A CSV file (Comma Separated Values file) is a type of plain text file that uses specific structuring to arrange tabular data. Because it’s a plain text file, it can contain only actual text data—in other words, printable ASCII or Unicode characters.\n",
    "\n",
    "The structure of a CSV file is given away by its name. Normally, CSV files use a comma to separate each specific data value. Here’s what that structure looks like:\n",
    "\n",
    "column 1 name,column 2 name, column 3 name\n",
    "first row data 1,first row data 2,first row data 3\n",
    "second row data 1,second row data 2,second row data 3\n",
    "...\n",
    "\n",
    "Notice how each piece of data is separated by a comma. Normally, the first line identifies each piece of data—in other words, the name of a data column. Every subsequent line after that is actual data and is limited only by file size constraints.\n",
    "In general, the separator character is called a delimiter, and the comma is not the only one used. Other popular delimiters include the tab (\\t), colon (:) and semi-colon (;) characters. Properly parsing a CSV file requires us to know which delimiter is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where Do CSV Files Come From?\n",
    "CSV files are normally created by programs that handle large amounts of data. They are a convenient way to export data from spreadsheets and databases as well as import or use it in other programs. For example, you might export the results of a data mining program to a CSV file and then import that into a spreadsheet to analyze the data, generate graphs for a presentation, or prepare a report for publication.\n",
    "\n",
    "CSV files are very easy to work with programmatically. Any language that supports text file input and string manipulation (like Python) can work with CSV files directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Files With csv\n",
    "Reading from a CSV file is done using the reader object. The CSV file is opened as a text file with Python’s built-in open() function, which returns a file object. This is then passed to the reader, which does the heavy lifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# dir(csv)\n",
    "# print(help(csv))\n",
    "csv_file= open('employee_birthday.txt')\n",
    "csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "for i in csv_reader:\n",
    "    print(i)\n",
    "    print (i[0])\n",
    "#     print \n",
    "print (csv_reader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# dir(csv)\n",
    "with open('employee_birthday.txt') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     print (csv_reader)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than deal with a list of individual String elements, you can read CSV data directly into a dictionary (technically, an Ordered Dictionary) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'John Smith'), ('department', 'Accounting'), ('birthday month', 'November')])\n",
      "OrderedDict([('name', 'Erica Meyers'), ('department', 'IT'), ('birthday month', 'March')])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_file=open('employee_birthday.txt', mode='r')\n",
    "csv_reader = csv.DictReader(csv_file)\n",
    "for row in csv_reader:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, department, birthday month\n",
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 3 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_birthday.txt', mode='r') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        print(f'\\t{row[\"name\"]} works in the {row[\"department\"]} department, and was born in {row[\"birthday month\"]}.')\n",
    "        line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "employee_file=open('employee_file4666.csv', mode='w')\n",
    "employee_writer = csv.writer(employee_file, delimiter=',', quotechar='*', quoting=csv.QUOTE_ALL)\n",
    "employee_writer.writerow(['John Smith', 'Accounting', 'November'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_file4561.csv', mode='w') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='*', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    employee_writer.writerow(['John Smith', 'Accounting', 'November'])\n",
    "    employee_writer.writerow(['Erica Meyers', 'IT', 'March'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quotechar optional parameter tells the writer which character to use to quote fields when writing. Whether quoting is used or not, however, is determined by the quoting optional parameter:\n",
    "\n",
    "If quoting is set to csv.QUOTE_MINIMAL, then .writerow() will quote fields only if they contain the delimiter or the quotechar. This is the default case.\n",
    "If quoting is set to csv.QUOTE_ALL, then .writerow() will quote all fields.\n",
    "If quoting is set to csv.QUOTE_NONNUMERIC, then .writerow() will quote all fields containing text data and convert all numeric fields to the float data type.\n",
    "If quoting is set to csv.QUOTE_NONE, then .writerow() will escape delimiters instead of quoting them. In this case, you also must provide a value for the escapechar optional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_file2.csv', mode='w') as csv_file:\n",
    "    fieldnames = ['emp_name', 'dept', 'birth_month']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'emp_name': 'John Smith', 'dept': 'Accounting', 'birth_month': 'November'})\n",
    "    writer.writerow({'emp_name': 'Erica Meyers', 'dept': 'IT', 'birth_month': 'March'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Categorical', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'ExcelFile', 'ExcelWriter', 'Expr', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int64Index', 'Interval', 'IntervalIndex', 'MultiIndex', 'NaT', 'Panel', 'Panel4D', 'Period', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseArray', 'SparseDataFrame', 'SparseList', 'SparseSeries', 'Term', 'TimeGrouper', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt64Index', 'WidePanel', '_DeprecatedModule', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_hashtable', '_lib', '_libs', '_np_version_under1p10', '_np_version_under1p11', '_np_version_under1p12', '_np_version_under1p13', '_np_version_under1p14', '_np_version_under1p15', '_tslib', '_version', 'api', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'datetime', 'datetools', 'describe_option', 'errors', 'eval', 'ewma', 'ewmcorr', 'ewmcov', 'ewmstd', 'ewmvar', 'ewmvol', 'expanding_apply', 'expanding_corr', 'expanding_count', 'expanding_cov', 'expanding_kurt', 'expanding_max', 'expanding_mean', 'expanding_median', 'expanding_min', 'expanding_quantile', 'expanding_skew', 'expanding_std', 'expanding_sum', 'expanding_var', 'factorize', 'get_dummies', 'get_option', 'get_store', 'groupby', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json', 'lib', 'lreshape', 'match', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'np', 'offsets', 'option_context', 'options', 'ordered_merge', 'pandas', 'parser', 'period_range', 'pivot', 'pivot_table', 'plot_params', 'plotting', 'pnow', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_msgpack', 'read_parquet', 'read_pickle', 'read_sas', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'reset_option', 'rolling_apply', 'rolling_corr', 'rolling_count', 'rolling_cov', 'rolling_kurt', 'rolling_max', 'rolling_mean', 'rolling_median', 'rolling_min', 'rolling_quantile', 'rolling_skew', 'rolling_std', 'rolling_sum', 'rolling_var', 'rolling_window', 'scatter_matrix', 'set_eng_float_format', 'set_option', 'show_versions', 'stats', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_msgpack', 'to_numeric', 'to_pickle', 'to_timedelta', 'tools', 'tseries', 'tslib', 'unique', 'util', 'value_counts', 'wide_to_long']\n",
      "             Name Hire Date   Salary  Sick Days remaining\n",
      "0  Graham Chapman  03/15/14  50000.0                   10\n",
      "1     John Cleese  06/01/15  65000.0                    8\n",
      "2       Eric Idle  05/12/14  45000.0                   10\n",
      "3     Terry Jones  11/01/13  70000.0                    3\n",
      "4   Terry Gilliam  08/12/14  48000.0                    7\n",
      "5   Michael Palin  05/23/13  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "print (dir(pandas))\n",
    "df = pandas.read_csv('hrdata.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Hire Date   Salary  Sick Days remaining\n",
      "Name                                                  \n",
      "Graham Chapman  03/15/14  50000.0                   10\n",
      "John Cleese     06/01/15  65000.0                    8\n",
      "Eric Idle       05/12/14  45000.0                   10\n",
      "Terry Jones     11/01/13  70000.0                    3\n",
      "Terry Gilliam   08/12/14  48000.0                    7\n",
      "Michael Palin   05/23/13  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', index_col='Name')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Hire Date   Salary  Sick Days remaining\n",
      "Name                                                   \n",
      "Graham Chapman 2014-03-15  50000.0                   10\n",
      "John Cleese    2015-06-01  65000.0                    8\n",
      "Eric Idle      2014-05-12  45000.0                   10\n",
      "Terry Jones    2013-11-01  70000.0                    3\n",
      "Terry Gilliam  2014-08-12  48000.0                    7\n",
      "Michael Palin  2013-05-23  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', index_col='Name', parse_dates=['Hire Date'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Hired   Salary  Sick Days\n",
      "Employee                                     \n",
      "Graham Chapman 2014-03-15  50000.0         10\n",
      "John Cleese    2015-06-01  65000.0          8\n",
      "Eric Idle      2014-05-12  45000.0         10\n",
      "Terry Jones    2013-11-01  70000.0          3\n",
      "Terry Gilliam  2014-08-12  48000.0          7\n",
      "Michael Palin  2013-05-23  66000.0          8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', \n",
    "            index_col='Employee', \n",
    "            parse_dates=['Hired'], \n",
    "            header=0, \n",
    "            names=['Employee', 'Hired','Salary', 'Sick Days'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing CSV Files With pandas\n",
    "Of course, if you can’t get your data out of pandas again, it doesn’t do you much good. Writing a DataFrame to a CSV file is just as easy as reading one in. Let’s write the data with the new column names to a new CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', \n",
    "            index_col='Employee', \n",
    "            parse_dates=['Hired'],\n",
    "            header=0, \n",
    "            names=['Employee', 'Hired', 'Salary', 'Sick Days'])\n",
    "df.to_csv('hrdata_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
